---
title: "Canadian Births Time Series Analysis"
author: "Andrew Saul"
editor: visual
format:
  html:
    code-fold: true
    code-summary: "Show the code"
    fig-numbering: true
    tbl-cap-location: top
editor_options: 
  chunk_output_type: console
---

```{r}
knitr::opts_chunk$set(echo = T, warning = F, message = F)

```

```{r}
#| echo = F
library(tidyverse)
library(lubridate)
library(fpp3)
library(fable)

```

```{r}
births_df <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-01-09/canada_births_1991_2022.csv')
```

## Introduction

This work was inspired from the Tidy Tuesday session titled "Canadian NHL Player Birth Dates" \[https://github.com/rfordatascience/tidytuesday/blob/main/data/2024/2024-01-09/readme.md\]. When I began analysing data for this project I discovered that Canadian birth data displayed both a trend and cyclical pattern in addition to seasonal fluctuations. Using the R package fpp3 \[https://otexts.com/fpp3/\], I wanted to discover the different components of the time series.

### Should births or birth rates be investigated?

The choice of variable is dependent upon the question being asked? A search using ChatGPT on this question revealed the following:

Live births are the measure of absolute organic (excluding migration) growth per measurement period that contribute to the population size. This value is utilised for economic and resource planning, such as determining demand for resources like healthcare, education, housing, and social services.

Live birth rate is the number of live births per 1,000 individuals in the population annually. It can be used for comparisons between countries or regions, regardless of population size. Birth rates are insightful for long-term analysis, especially in aging societies or declining populations

For the purposes of this blog I will investigate births only

### Goals of blog

The goals of this blog are two-fold. Primarily I am interested in developing code to reveal birth data insights. Secondly, I am interested in revealing components of the time series.

## Birth data

In order to examine time-series data with the fpp3 package, the tibble data needs to be converted into a **tsibble** object. Details can be viewed at \[https://otexts.com/fpp3/tsibbles.html\]

```{r}
ts_births <- 
births_df %>% 
  # create new column as year-month character - then convert it to a mth type using yearmonth function
  mutate(ymdate = yearmonth(paste(year, month))) %>% 
  as_tsibble(index = ymdate)
```

```{r}
#| label: fig-fig1
#| fig-cap: "Canadian births"

ts_births %>% 
  autoplot(births)+
  labs(x = "Year/Month",
       y = "Births",
       title = "Canadian Registered Births")
```

### Seasonality

We can investigate the seasonality of the plot using the ggseason function

```{r}
#| label: fig-fig2
#| fig-cap: "Seasonality separated into years"

ts_births %>% 
  gg_season(births, labels = "both")
```

In @fig-fig2, each year is plotted separately. However, with over 30 lines this plot is difficult to interpret. Instead, seasonality can be plotted by facetting the ggplot into months.

```{r}
#| label: fig-fig3
#| fig-cap: "Seasonality: trends observed for each month"
ts_births %>% 
  gg_subseries(births, labels = "both")
```

In @fig-fig3 it appears that most births occur in July (summer) and the fewest births occur in February (winter). One can also see from this plot that births peaked at the beginning of the time series and decreased to a minimum around 2001. From 2007 until 2021 the birth rate stabilised at a relatively high level, but fell once again for the final recorded year of 2022.

## Correlations

An assumption of time series modelling is that the previous time point(s) influence the current time point.

```{r}
#| label: fig-lag
#| fig-cap: "Lag in months"
ts_births %>% 
  gg_lag(births, lag = 1:12)+
  labs(x = "lag(birth, y_t)", y = "lag(birth, y_t-k")
  
```

@fig-lag represents the correlation between time points separated by months, depicted by the lag number. We can see that there is a strong, maximum correlation between time points separated by one year. This indicates yearly seasonal variation.

### Autocorrelation Function (ACF)

```{r}
#| label: fig-acf
#| fig-cap: "Correlogram"
ts_births %>% 
  ACF(births) %>% 
  autoplot() +
  labs(title = "Canadian monthly birth data")
```

The ACF depicts the relationships we see in the lag plots. A slow decline in ACF values vs lag number indicates that the value from the current time point is substantially influenced by values of time points both close and distant. A repeated pattern of increased ACF values indicate a seasonal component in the series. In figure @fig-acf both trend and seasonality are present. The repeated pattern in the ACF indicates a large seasonal component. As this repeated pattern peaks at 12 and 24 months, the seasonal component is yearly. The gradual reduction in ACF value is due to the trend component.

## Time Series Decompostion

# Transformations

When viewing  @fig-fig1, the amount of variation should be consistant. For instance, the seasonal variation amplitude may increase by a constant factor over time. In order to maintain consistant variation, a transformation may be required.

```{r}
lambda <- 
  ts_births %>% 
  features(births,features = "guerrero") %>% 
  pull(lambda_guerrero)

ts_births_bc <- 
  ts_births %>% 
  mutate(BC_births = box_cox(births, lambda))

ts_births_bc %>% 
  autoplot(BC_births)+
    labs(y = "",
       title = (paste0(
         "Transformed gas production with \\lambda = ",
         round(lambda,2))))


```

For the population data, a box-cox transformation value was calculated to be `r lambda`. However, the variation seen in @fig-fig1 appeared consistant, so data transformation was not implemented.

### STL decomposition (Seasonal and Trend decomposition using Loess)

This involves splitting up the data into trend/cyclical, seasonal and residual components. If it has been ascertained that the decomposition is multiplicative then components will need to be transformed. The Canadian population data appears additive and no transformation is deemed necessary.

```{r}
 dcmp <- 
  ts_births_bc %>% 
  model(stl = STL(births))
```

```{r}
#| label: fig-trendoverlay
#| fig-cap: "Trend pattern overlaying the data"
components(dcmp) |>
  as_tsibble() |>
  autoplot(births, colour="gray") +
  geom_line(aes(y=trend), colour = "#D55E00") +
  labs(
    y = "Births",
    title = "Canadian Birth Data"
  )
```

@fig-trendoverlay demonstrates the trend component overlaying the complete plot.

```{r}
#| label: fig-stl
#| fig-cap: "STL decomposition"
#| 
 ts_births_bc %>% 
  model(stl = STL(births, robust = F)) %>% 
  components() %>% autoplot()
```

@fig-stl is a representation of the plot divided into the three STL components. The trend component is maximum at the beginning of the trace, then decreases to its minimum, finally regaining most of its gains with a period of stability before decreasing during the covid period. It is noteworthy that the seasonal component can change slowly over time. The bars on the side of each plots have the same length.

## Forecasting

Baseline (simple) forecasting methods include the mean, naive and seasonal naive methods. These methods often act as benchmarks to more complicated techniques

```{r}
#| label: fig-benchmark
#| fig-cap: "Benchmark forecast methods"

# set training data before 2018
train <- 
  ts_births %>% 
  filter(year <2018)

#set period for forecast data
pred_pop <- 
  ts_births %>% 
  filter(year >=2018)

#fit data
pop_fit <- 
  train %>% 
  model(
    Mean = MEAN(births),
    `Naïve` = NAIVE(births),
    `Seasonal naïve` = SNAIVE(births),
    Drift = NAIVE(births ~ drift())
  )

# produce forecasts for period 2019-2022
pop_2019_22 <- 
  pop_fit %>% 
  forecast(new_data = pred_pop)

# plot data with forecasts
pop_2019_22 %>% 
  autoplot(ts_births %>% filter(year >=2014), level = NULL)+
  autolayer(pred_pop, births, color = "black")
```

@fig-benchmark demonstrates four methods of benchmark forecasting. The mean method forecasts all future values as the average of all historical values. The Naive method forecasts all future values as the last observed value. The naive-seasonal method forecasts each new value to be equal to the last observed value from the same season. The drift method allows changes to increase or decrease in time, where the gradient is set as the average change seen in the historical data. In this figure the last four years were forecasted using the fourn methods.

## Exponential Smoothing

Historically this technique has often been used for forecasting. Forecasts are produced by weighting past observations in an exponential manner. That is, the more recent the observation, the greater the weighting towards the forecast. A list of exponential smoothing factors are noted in chapter 8.4 of the fpp3 webbook.

```{r}
#| label: tbl-esacc
#| tbl-cap: Accuracy of Holt-Winters vs Holt-linear methods

ts_births %>% 
  filter(year<2019) %>% 
  model(
    hw = ETS(births ~ error("A") + trend("Ad") + season("A")),
    hl = ETS(births ~ error("A") + trend("A") + season("A"))
  ) %>% 
  forecast(h = "48 months") %>% 
  accuracy(ts_births)
```

In @tbl-esacc the RMSE and MAE is lower for the holt-linear method (no dampening) so this method will be further investigated.

```{r}
#| label: fig-expsmooth
#| fig-cap: "Seasonal Additive Exponential Smoothing with Trend Dampening"

#   ts_births %>% 
#   model(
#     hl = ETS(births ~ error("A") + trend("A") + season("A"))
#   ) %>% 
# tidy()  

ts_births %>% 
  filter(year<2019) %>% 
  model(
    hl = ETS(births ~ error("A") + trend("A") + season("A"))
  ) %>% 
  forecast(h = "48 months") %>% 
autoplot(ts_births |> filter(between (ymdate, yearmonth("2018 Jan"), yearmonth("2022 Dec"))))+
  labs(title = "80 & 95 % prediction intervals for Canadian population for 2019-2022",
       x = "Date")
```

The 80% and 95% confidence intervals calculated using the holt-linear method are displayed in @fig-expsmooth. The ETS function utilises state-space modelling to calculate the confidence intervals.